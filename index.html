<!DOCTYPE html>
<html>


<style>
.has-text-red {
color: #bf5700;
}

.s {
color: #d14
}

.na {
color: #008080
}

.nc {
color: #445588;
font-weight: bold
}

.nl {
color: #990000;
font-weight: bold
}
</style>
	
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Casper: Assistive Teleoperation of Mobile Manipulators with Open-World Intent Inference">
  <meta name="keywords" content="Assistive Teleoperation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Casper: Assistive Teleoperation of Mobile Manipulators with Open-World Intent Inference</title>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Casper: Assistive Teleoperation of Mobile Manipulators with Open-World Intent Inference</h1>
          
          <div class="is-size-5 publication-authors">
		      <span class="author-block" style="font-size: 25px;">Anonymous Authors</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Assistive teleoperation, where control is shared between a human and a robot, enables efficient and intuitive human-robot collaboration in complex, unstructured environments. A central challenge in real-world assistive teleoperation is open-world intent inference, where the robot must interpret a wide range of human intentions from user inputs and act appropriately across diverse, unstructured environments. Existing methods are confined to simple, predefined scenarios or lack the generalization capacity for real-world variability, limiting their support for complex long-horizon tasks. We introduce Casper, an assistive teleoperation system that leverages commonsense knowledge from pre-trained visual language models (VLMs) for real-time open-world intent inference and task execution. From a short snippet of teleoperated user input, Casper infers user intent, takes over the control when confident, instantiates a parameterized skill from its skill library, and autonomously executes the task to fulfill the intent. Casper includes an open-world perception module for generalized understanding of novel objects and scenes, a novel open-world intent inference mechanism that infers how to interact with the objects using commonsense reasoning, and a skill library that expands the scope of prior assistive teleoperation systems to support diverse, long-horizon mobile manipulation tasks. Extensive empirical evaluation, including human studies and system ablations, demonstrates that Casper improves task performance, reduces human cognitive load, and achieves higher user satisfaction than direct teleoperation and assistive teleoperation baselines.
          </p>
          <br>
          <br>
        </div>
      </div>
    </div>
</body>
</html>
